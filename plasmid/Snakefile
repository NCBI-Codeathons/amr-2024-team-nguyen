#!/usr/bin/env snakemake
#
# Analyze all-ast contigs for plasmids
#
import pandas as pd
import os

######################################################################
#
# set up enviroment and sample list
#
######################################################################

#
# ---------------- INPUTs ----------------
#
DATASET_DIR="/home/nbowers/bvbrc-dev/dev_container/NCBI_AMR_Codeathon/all-ast"
CAT_FILENAME="dataset_catalog.json"
TEST_CAT_FILENAME="/home/ac.curtish/NCBI_AMR_Codeathon/my-ast/dataset_catalog.head.json"
#
# ---------------- OUTPUTS ----------------
#
#OUT_DIR="/home/ac.curtish/NCBI_AMR_Codeathon/all-plasmid/out"
OUT_DIR="out"
 
#
# ----------------- SAMPLE LIST -----------
#
include: "rules/parse_dataset_catalog.py"

# load sample accessions/filenames from the catalog.json
samplesRawDf = parse_ast_catalog(DATASET_DIR+"/"+CAT_FILENAME)
#samplesRawDf = parse_ast_catalog(TEST_CAT_FILENAME)

# FNA version with just filenames
samplesRawDf["FNAF"] = samplesRawDf["FNA"].apply(os.path.basename)

# denovo and  version with just filenames
samplesRawDf["FNAF"] = samplesRawDf["FNA"].apply(os.path.basename)

# derived files
samplesRawDf["FNAdenovo"] = samplesRawDf['FNAdenovo'] = samplesRawDf['FNA'].str.replace(r'\.fna$', '.denovo.fna', regex=True)
samplesRawDf["FNAguided"] = samplesRawDf['FNAguided'] = samplesRawDf['FNA'].str.replace(r'\.fna$', '.guided.fna', regex=True)

# load our blacklist of accessions to ignore
blacklist = pd.read_csv("accessions_blacklist.tsv", sep='\t')

# Filter out rows in samplesRaw where the 'accession' is in the blacklist
samplesDf = samplesRawDf[~samplesRawDf['accession'].isin(blacklist['accession'])]
print("Filtered Samples (blacklist): {0} rows, {1} columns.".format(*samplesDf.shape))

# head, for faster debugging
headN=10000000
#headN=10 
samplesDf = samplesDf.head(n=headN)
print("Head Samples: {0} rows, {1} columns.".format(*samplesDf.shape))

# convert to list of zip for use with input: expand("{sample.FNA}",sample=samplesTup.tupples())
samplesTup   = list(zip(*[samplesDf[col] for col in samplesDf.columns]))

######################################################################
#
# RULES
#
######################################################################

rule help: 
	run:
		print("--- help ----")
		print("help: list top targets")
		print("test: show top 10 samples")
		print("wc: test running wc on top 100 fnas")
		print("")

rule test: 
	run: 
		print(samplesDf.head(n=10))


# ----------------------------------------------------------------------
# 
# "wc" - test process
#
# process top 100 non-blacklisted samples
#
# ----------------------------------------------------------------------

#
# top level rule - samples to run
#
rule wc: 
	input: expand(OUT_DIR + "/{accession}.txt", accession=samplesDf['accession'].head(n=10))

#
# wc test process
# 
# get wc for assembly fna
#
rule wc_proc_lamdba:
	wildcard_constraints: ACC="GCA_[0-9]+\\.[0-9]+"
	output: OUT_DIR+"/{ACC}.txt"
	input: lambda wildcards: os.path.join(DATASET_DIR,samplesDf.loc[samplesDf['accession'] == wildcards.ACC, 'FNA'].values[0])
	shell: "grep -H -c '>' {input} > {output}"

rule wc_proc_no_lambda:
	wildcard_constraints: ACC="GCA_[0-9]+\\.[0-9]+"
	output: OUT_DIR+"/{ACC}_{EXTRA}.txt"
	input: DATASET_DIR+"/{ACC}/{ACC}_{EXTRA}"
	#input: lambda wildcards: samplesDf.loc[samplesDf['accession'] == wildcards.accession, 'FNA'].values[0]
	shell: "grep -H -c '>' {input} > {output}"

# ----------------------------------------------------------------------
# 
# "XIOAHUI" plasmid finder
#
# process top 1 non-blacklisted samples
#
# extracted from ../plasmid_chromosome_phage/pred_all/runModels.sh
# ----------------------------------------------------------------------

PLASMID_X_DIR="../plasmid_chromosome_phage/pred_all"

#
# top level target
# 
# for now, just first sample

rule plasmids_x:
	input:
		raw=expand(OUT_DIR + "/{accession}/{accession}.denovo.fna.zou.pred.tab",accession=samplesDf['accession']),
		summary= ""


# ......................................................................
#
# split contig into 5k chunks
# 
# subsampleFastas.py DIR/
#    files must end in .fasta
#    all .fasta in directory will be processed
#    output will be .sub.fasta files in the same directory
#
# ......................................................................

#
# create source dir of fastas to processs: split program requires a dir of *.fasta
#
# sub
rule plasmid_x_setup_denovo_src_dir:
        output: OUT_DIR+"/{ACC}/{ACC}.denovo.fna"
        input: lambda wildcards: os.path.join(DATASET_DIR,samplesDf.loc[samplesDf['accession'] == wildcards.ACC, 'FNAdenovo'].values[0])
        shell: "ln -s {input} {output}"

rule plasmid_x_setup_guided_src_dir:
        output: OUT_DIR+"/{ACC}/{ACC}.guided.fna"
        input: lambda wildcards: os.path.join(DATASET_DIR,samplesDf.loc[samplesDf['accession'] == wildcards.ACC, 'FNAguided'].values[0])
        shell: "ln -s {input} {output}"

#
# Split multi-contig fasta files into contig-specific fastas
#
rule plasmid_x_split_denovo_contig:
        output: OUT_DIR+"/{ACC}/{ACC}.denovo.fna.split/list.txt"
        input:  OUT_DIR+"/{ACC}/{ACC}.denovo.fna"
        shell:
                "python {PLASMID_X_DIR}/splitFasta.py {input}"
                " && "
                "find $(dirname {output}) -name '*.fasta' -exec grep '>' {{}} + > {output}"

rule plasmid_x_split_guided_contig:
        output: OUT_DIR+"/{ACC}/{ACC}.guided.fna.split/list.txt"
        input:  OUT_DIR+"/{ACC}/{ACC}.guided.fna"
        shell:
                "python {PLASMID_X_DIR}/splitFasta.py {input}"
                " && "
                "find $(dirname {output}) -name '*.fasta' -exec grep '>' {{}} + > {output}"


rule plasmid_x_analyze_sample_kmc:
    input:
        denovo_fa=OUT_DIR+"/{ACC}/{ACC}.denovo.fna",
        denovo_split=OUT_DIR+"/{ACC}/{ACC}.denovo.fna.split/list.txt",
        guided_fa=OUT_DIR+"/{ACC}/{ACC}.guided.fna",
        guided_split=OUT_DIR+"/{ACC}/{ACC}.guided.fna.split/list.txt",
        script="scripts/plasmid_x.sh"
    output:
        denovo=OUT_DIR+"/{ACC}/{ACC}.denovo.fna.zou.pred.tab",
        guided=OUT_DIR+"/{ACC}/{ACC}.guided.fna.zou.pred.tab"
    shell:
        # denovo
        "{input.script} $PWD/{PLASMID_X_DIR} $PWD/{input.denovo_fa} $PWD/$(dirname {input.denovo_fa})"
        " && "
        # guided
        "{input.script} $PWD/{PLASMID_X_DIR} $PWD/{input.guided_fa} $PWD/$(dirname {input.guided_fa})"
        
rule plasmid_x_summarize_sample:
    input:
        denovo=OUT_DIR+"/{ACC}/{ACC}.denovo.fna.zou.pred.tab",
        guided=OUT_DIR+"/{ACC}/{ACC}.guided.fna.zou.pred.tab",
        script="scripts/merge_zou_pred.py"
    output:
        all=OUT_DIR+"/{ACC}/{ACC}.zou.pred.clean.all.tsv",
        denovo=OUT_DIR+"/{ACC}/{ACC}.zou.pred.clean.denovo.tsv"
    shell:
        # denovo only
        "{input.script} -in_dir $(dirname {output.denovo}) -denovo_pat '*.denovo.fna.zou.pred.tab' -guided_pat '*.NONE.fna.zou.pred.tab' -out_tsv {output.denovo}"
        " && "
        # all: denovo & guided
        "{input.script} -in_dir $(dirname {output.denovo}) -denovo_pat '*.denovo.fna.zou.pred.tab' -guided_pat '*.guided.fna.zou.pred.tab' -out_tsv {output.all}"
    
#
# a simple awk script turned out to be orders of magnitude faster
# than my python script, or a distributed use of the python script
# to create clean tsvs for each sample....
#
# This merges, and cleans, at the same time.
#
# !!! ICK: genome_acc is extract from the filename!!!!
#
rule plasmid_x_summarize_all_samples_fast:        
    input:
        script="scripts/merge_clean_zou_pred.awk",
        files=expand(OUT_DIR + "/{accession}/{accession}.denovo.fna.zou.pred.tab", accession=samplesDf['accession'])
    output:
        denovo="merged.cleaned.denovo.zou.pred.tsv"
        guided="merged.cleaned.guided.zou.pred.tsv"
    shell:
        "echo '# denovo' && "
        "time "
        "find out -name '*.denovo.fna.zou.pred.tab' "
        " -exec awk -v ASM_TYPE=denovo -f {input.script} {} + "
        "| awk 'BEGIN{FS = OFS = "\t"}(NR>1&&$1!="genome_acc"){print $0}' "
        "> {outout.denovo}"
        " && "
        "echo '# guided' && "
        "time "
        "find out -name '*.guided.fna.zou.pred.tab' "
        " -exec awk -v ASM_TYPE=guided -f {input.script} {} + "
        "| awk 'BEGIN{FS = OFS = "\t"}(NR>1&&$1!="genome_acc"){print $0}' "
        "> {outout.guided}"
# ----------------------------------------------------------------------
# 
# "Plasmid Finder"
#
# https://github.com/genomicepidemiology/plasmidfinder
#
# ----------------------------------------------------------------------

rule plasmids_pf:
    input: expand(OUT_DIR + "/{accession}/{accession}.denovo.fna.pf/data.json", accession=samplesDf['accession'])

rule plasmid_pf_analyze:
    input:
        denovo_fa=OUT_DIR+"/{ACC}/{ACC}.denovo.fna",
        guided_fa=OUT_DIR+"/{ACC}/{ACC}.guided.fna",
    output:
        denovo=OUT_DIR+"/{ACC}/{ACC}.denovo.fna.pf/data.json",
        guided=OUT_DIR+"/{ACC}/{ACC}.guided.fna.pf/data.json"
    shell:
        # activate env
        "("
        "source ~/miniconda3/etc/profile.d/conda.sh "
        " && "
        "conda activate ../plasmid_finder/conda_pf "
        " && "
        # denovo
        #"./scripts/plasmid_pf.sh ../plasmid_finder {input.denovo_fa} $(dirname {output.denovo}) "
        #"plasmidfinder.py -i {input.denovo_fa} -o $(dirname {output.denovo}) "
        "if [ -s {input.denovo_fa} ]; then plasmidfinder.py -i {input.denovo_fa} -o $(dirname {output.denovo}); else touch {output.denovo}; fi "
        " && "
        # guided
        #"./scripts/plasmid_pf.sh ../plasmid_finder {input.guided_fa} $(dirname {output.guided}) "
        #"plasmidfinder.py -i {input.guided_fa} -o $(dirname {output.guided}) "
        "if [ -s {input.guided_fa} ]; then plasmidfinder.py -i {input.guided_fa} -o $(dirname {output.guided}); else  touch {output.guided}; fi "
        ")"

# ----------------------------------------------------------------------
# 
# All plasmid finders
#
# ----------------------------------------------------------------------

rule plasmids:
    input:
        xioahui_finder=rules.plasmids_x.input,
        plasmidfinder=rules.plasmids_pf.input
     
